{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import reqd libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#os or pathlib for extracting images in different folders\n",
    "import os\n",
    "#keras for dealing with images\n",
    "from keras.preprocessing import image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=Path(\"Desktop\\images\")\n",
    "#now p is the path to our data set folder named images which contains 4 folders i.e cats, dogs, horses, humans\n",
    "#glob fn gives the files/folders of type we entered. * means all files/folders\n",
    "dirs=p.glob(\"*\")\n",
    "labels_dict={\"cat\":0,\"dog\":1,\"horse\":2,\"human\":3}\n",
    "l_dict={0:\"cat\",1:\"dog\",2:\"horse\",3:\"human\"}\n",
    "#to stores images and their corresponding labels\n",
    "image_data=[]\n",
    "labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traverse for folder paths in dirs\n",
    "for folder_name in dirs:\n",
    "    label=str(folder_name).split('\\\\')[-1][:-1]\n",
    "    #folder_name is of type path so convert it to string and we need only last word i.e for eg cats out of which we remove 's' from all\n",
    "    #print(label)\n",
    "    #now traverse in each of these folders. we need only images so use jpg in glob\n",
    "    for img_path in folder_name.glob(\"*.jpg\"):\n",
    "        #print(img_path)\n",
    "        #load the image using keras and fix its size as images maybe of differnent sizes\n",
    "        img=image.load_img(img_path,target_size=(32,32))\n",
    "        #convert image to array\n",
    "        img_array=image.img_to_array(img)\n",
    "        #append the image to image data\n",
    "        image_data.append(img_array)\n",
    "        #append the corresponding label to labels list\n",
    "        labels.append(labels_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that length of both image_data and labels is same i.e 808 in our case\n",
    "#print(len(labels))\n",
    "#print(len(image_data))\n",
    "#convert image data to numpy array..\n",
    "#since we will plot it on matplotlib so all values should be between 0-1 and also convert it to float\n",
    "image_data=np.array(image_data,dtype='float32')/255.0\n",
    "labels=np.array(labels)\n",
    "#print(image_data)\n",
    "#print(image_data.shape,labels.shape)\n",
    "#by shape we see that their are 808 examples with 100*100 size and 3 channels\n",
    "#now shuffle the dataset.. corresponding labels should stay the way they are\n",
    "#so combine them into one and then shuffle\n",
    "#to combine we zip, then shuffle and unzip\n",
    "combined=list(zip(image_data,labels))\n",
    "random.shuffle(combined)\n",
    "#unzip\n",
    "image_data[:],labels[:]=zip(*combined)\n",
    "#check for some images\n",
    "#for i in range(10):\n",
    "    #plt.imshow(image_data[i])\n",
    "    #does not show axis with image\n",
    "    #plt.axis('off')\n",
    "    #plt.title(str(labels[i]))\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM Code with only 2 classes i.e -1 & 1\n",
    "class SVM:\n",
    "    def __init__(self,C=1.0):\n",
    "        #C->hyperparameter\n",
    "        self.C = C\n",
    "        #W-> weights\n",
    "        self.W = 0\n",
    "        #b->bias\n",
    "        self.b = 0\n",
    "        \n",
    "    def hingeLoss(self,W,b,X,Y):\n",
    "        loss  = 0.0\n",
    "        \n",
    "        loss += .5*np.dot(W,W.T)\n",
    "        \n",
    "        m = X.shape[0]\n",
    "        \n",
    "        for i in range(m):\n",
    "            ti = Y[i]*(np.dot(W,X[i].T)+b)\n",
    "            loss += self.C *max(0,(1-ti))\n",
    "            \n",
    "        return loss[0][0]\n",
    "    \n",
    "    def fit(self,X,Y,batch_size=100,learning_rate=0.00001,maxItr=1000):\n",
    "        \n",
    "        no_of_features = X.shape[1]\n",
    "        no_of_samples = X.shape[0]\n",
    "        \n",
    "        n = learning_rate\n",
    "        c = self.C\n",
    "        \n",
    "        #Init the model parameters\n",
    "        W = np.zeros((1,no_of_features))\n",
    "        bias = 0\n",
    "        \n",
    "        #Initial Loss\n",
    "        \n",
    "        #Training from here...\n",
    "        # Weight and Bias update rule!\n",
    "        losses = []\n",
    "        \n",
    "        for i in range(maxItr):\n",
    "            #Training Loop\n",
    "            \n",
    "            l = self.hingeLoss(W,bias,X,Y)\n",
    "            losses.append(l)\n",
    "            ids = np.arange(no_of_samples)\n",
    "            np.random.shuffle(ids)\n",
    "            \n",
    "            #Batch Gradient Descent(Paper) with random shuffling\n",
    "            for batch_start in range(0,no_of_samples,batch_size):\n",
    "                #Assume 0 gradient for the batch\n",
    "                gradw = 0\n",
    "                gradb = 0\n",
    "                \n",
    "                #Iterate over all examples in the mini batch\n",
    "                for j in range(batch_start,batch_start+batch_size):\n",
    "                    if j<no_of_samples:\n",
    "                        i = ids[j]\n",
    "                        ti =  Y[i]*(np.dot(W,X[i].T)+bias)\n",
    "                        \n",
    "                        if ti>1:\n",
    "                            gradw += 0\n",
    "                            gradb += 0\n",
    "                        else:\n",
    "                            gradw += c*Y[i]*X[i]\n",
    "                            gradb += c*Y[i]\n",
    "                            \n",
    "                #Gradient for the batch is ready! Update W,B\n",
    "                W = W - n*W + n*gradw\n",
    "                bias = bias + n*gradb\n",
    "                \n",
    "        \n",
    "        self.W = W\n",
    "        self.b = bias\n",
    "        return W,bias,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we are using a binary classifier! So convert data for One-Vs-One Classifier\n",
    "#So we will make a data dictionary... in which we will map class label with its data\n",
    "n_samples=image_data.shape[0]\n",
    "#flatten the image data to store it in the form of a single row \n",
    "image_data=image_data.reshape((n_samples,-1))\n",
    "#now shape is 808,3072\n",
    "#print(image_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a fn to create data classwise i.e all cat examples with cat label, all dog pics with dog label\n",
    "def classWiseData(image_data,labels):\n",
    "    #initialise an empty dictionary\n",
    "    data={}\n",
    "    #number of classes\n",
    "    classes=len(np.unique(labels))\n",
    "    #initialise each label in dictionary\n",
    "    for i in range(classes):\n",
    "        data[i]=[]\n",
    "    for i in range(labels.shape[0]):\n",
    "        data[labels[i]].append(image_data[i])\n",
    "    #now in data dictionary we have labels mapped to list of numpy arrays \n",
    "    #convert these lists to numpy array\n",
    "    for j in data.keys():\n",
    "        data[j]=np.array(data[j])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=classWiseData(image_data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will take data of 2 labels and  prepare the data for svm i.e marks one label as 1 & other as -1 i.e Y  and combine features to get X\n",
    "#it combines data of two classes into single matrix\n",
    "def GetDataPairForSVM(data_1,data_2):\n",
    "    #no of samples in each label\n",
    "    l1,l2=data_1.shape[0],data_2.shape[0]\n",
    "    #total no of samples\n",
    "    n_samples=l1+l2\n",
    "    n_features=data_1.shape[1]\n",
    "    #here data_pair is X & data_lables is Y\n",
    "    data_pair=np.zeros((n_samples,n_features))\n",
    "    data_labels=np.zeros((n_samples,))\n",
    "    #copy the data from data_1 & data_2\n",
    "    data_pair[:l1,:]=data_1\n",
    "    data_pair[l1:,:]=data_2\n",
    "    #data_1 class labelled as -1 & data_2 class labelled as 1\n",
    "    data_labels[:l1]=-1\n",
    "    data_labels[l1:]=1\n",
    "    return data_pair,data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Nc2 number of svm's for one vs one classification\n",
    "mysvm=SVM()\n",
    "#instead of making nc2 svm's we use a single svm object, train it , store its wts and bias, then again train it with some other pair of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it will return a dictionary of weights and biases\n",
    "def trainSVMs(data,labels):\n",
    "    #initailise an empty dict\n",
    "    svm_classifiers={}\n",
    "    #number of classes\n",
    "    n_classes=len(np.unique(labels))\n",
    "    #to go to each pair we use loop i->n & j from i+1->n\n",
    "    for i in range(n_classes):\n",
    "        #initialise an empty dictionary for i as label 1(isme j change hota rahega)\n",
    "        svm_classifiers[i]={}\n",
    "        for j in range(i+1,n_classes):\n",
    "            #now we take data of label i and label j and make it suitable for SVM\n",
    "            x,y=GetDataPairForSVM(data[i],data[j])\n",
    "            #train the model using this data\n",
    "            wts,b,loss=mysvm.fit(x,y)\n",
    "            #store the weights and bias in this dictionary as a tuple\n",
    "            svm_classifiers[i][j]=(wts,b)\n",
    "    #return this dictionary of weights and biases\n",
    "    return svm_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the SVM's\n",
    "svm_classifiers=trainSVMs(data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6113861386138614\n"
     ]
    }
   ],
   "source": [
    "#parameters for cats & dogs\n",
    "#cats_dogs=svm_classifiers[0][1]\n",
    "#wts=cats_dogs[0]\n",
    "#bias=cats_dogs[1]\n",
    "classes=len(np.unique(labels))\n",
    "def binaryPredict(x,w,b):\n",
    "    z=np.dot(x,w.T)+b\n",
    "    if z>=0:\n",
    "        return 1\n",
    "    else :\n",
    "        return -1\n",
    "def predict(X):\n",
    "    count=np.zeros((classes,))\n",
    "    #we will count ki each classifier given testing point ko kaunsi class me batata hai and then take the maxm of those\n",
    "    for i in range(classes):\n",
    "        for j in range(i+1,classes):\n",
    "            w,b=svm_classifiers[i][j]\n",
    "            #Take a majority prediction from each of classifier\n",
    "            #now take its prediction from svm. it will return 1 or -1\n",
    "            #we know that we kept 1 for j and -1 for i( see getpairdataforsvm function)\n",
    "            z=binaryPredict(X,w,b)\n",
    "            if z==1 :\n",
    "                count[j]+=1\n",
    "                #increment count of j if prediction is in its favour\n",
    "            else :\n",
    "                count[i]+=1\n",
    "    final_prediction=np.argmax(count)\n",
    "    return final_prediction\n",
    "\n",
    "count=0\n",
    "for i in range(image_data.shape[0]):\n",
    "    if(predict(image_data[i])==labels[i]):\n",
    "        count+=1\n",
    "accuracy=count/image_data.shape[0]\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
